software rendering gives us a lot more flexibility,
  because we won't be limited by a hardware implementation,
  with triangle only rasterization, isolated shader programs, and fixed size buffers
GPU equivalent performance can be achieved using SIMD ("https://en.wikipedia.org/wiki/SIMD")
"https://www.quora.com/What-is-the-main-difference-between-SIMD-and-GPU"
"https://stackoverflow.com/questions/27333815/cpu-simd-vs-gpu-simd"
"https://en.wikipedia.org/wiki/Vector_processor"
"https://en.wikipedia.org/wiki/RISC-V#Vector_set"

graphical objects are made of primitives
  each primitive has a specific algorithm for rasterization
2d primitives: point, line, curve, triangle, curved area
3d objects made of flat surfaces will be broken up into triangles
3d objects made of curved surfaces can be broken up into a number of primitive 3d surfaces,
  which can be easily projected to 2d
"https://en.wikipedia.org/wiki/Quadric"
also interpolation is a good method for amorphous surfaces

2d objects will be rasterized into pixels (a pixel is a coordinate plus a color value)
then these rasterized objects will be drawn in the framebuffer,
  in layers over each other (in an overlay on top of all 3d objects)
rasterizing 3d objects, produces an array of fragments
  a fragment, besides color, contains a normal and a depth
when creating the pixels of the framebuffer from the fragments,
  the normals are used for lighting, and the depths are used for z'buffer

graphical objects are of 2 kinds:
, those which we know will remain unchanged the next time we want to draw to the framebuffer
  these objects are first rasterized into memory, then we copy it into framebuffer
, those which we know will be changed (scaled, rotated, moved in z direction),
  the next time we want to draw to the framebuffer (which happens a lot for animations with high frame rate)
  these objects will be drawn directly to the framebuffer
(framebuffer uses double buffering and v'sync)
note that if an object just moves in x'y plane (without rotation), the cached rasterization is still useful
  for 2d objects we simply add a constant to the position of all pixels
  for 3d objects we may additionally want to recompute the lighting of pixels from fragments

data structure for graphical objects:
, primitives
, material
, cached rasterization (can be none)

with a scene graph we can have fine grained graphical objects which can be combined easily

"https://en.wikipedia.org/wiki/Midpoint_circle_algorithm"
"https://en.wikipedia.org/wiki/Xiaolin_Wu%27s_line_algorithm"
"http://members.chello.at/~easyfilter/bresenham.html"
"https://nothings.org/gamedev/rasterize/"
"https://magcius.github.io/xplain/article/"
"https://en.wikipedia.org/wiki/Stencil_buffer"
"https://www.scratchapixel.com"
"https://www.scratchapixel.com/lessons/3d-basic-rendering/phong-shader-BRDF"

"https://github.com/rust-windowing/winit"
"https://github.com/kas-gui/kas"
"https://github.com/sebcrozet/kiss3d"
"https://github.com/three-rs/three"
"https://crates.io/crates/rust-3d"
"https://github.com/38/plotters"
"https://github.com/rustsim/nphysics"
